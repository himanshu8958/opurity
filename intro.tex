\section{Introduction}

We say that a procedure in an imperative programming language is
\emph{observationally pure} (OP) if for each specific argument value it has
a specific return value, across all possible sequences of calls to the
procedure, irrespective of what other code runs between these calls.  In
other words, there exists a mathematical function such that the argument to
return-value behavior of the procedure mimics this function. Observational
purity is a useful property, as OP procedures can be memoized, and
statements that call OP procedures can be subject to code motion, code
optimization, etc.

Any procedure whose code is deterministic and that does not read any
pre-existing state other than its arguments is trivially OP. Also, any
procedure that uses global variables but does not involve looping or
recursion is easy to verify whether it is OP. However, in general, many
procedures, especially ones in libraries, update and read global variables,
typically to optimize their own behavior, while still mimicking
mathematical functions in terms of input-output behavior. At the same time,
they also use looping or recursion. In this paper, we focus on the more
general problem of checking observational purity of procedures that read
and write global variables and that may make use of recursion.

\subsection{Motivating Example}

\begin{lstlisting}[language=c, caption= {Procedure `factCache' :
      returns n! and memoizes result for last argument seen.},
    label=lst:factorialSimple]
  
int g = -1;
int lastN = 0;
int factCache( int n) {
  if(n <= 1) {
    return 1;
  } else if (g != -1 && n == lastN) {
    return g;
  } else {
    g = n * factCache( n - 1 );
    lastN = n;
    return g;
  }
}
\end{lstlisting}

Let us consider the example procedure `factCache' in
Listing~\ref{lst:factorialSimple}, which we use as our running example. It
returns n! for the given argument n, and caches the return value for the
last argument provided to it. It uses two ``private'' global variables to
implement the caching -- g, and lastN. g is initialized to -1, and after
the first call to the procedure onwards is used to store the return value
from the most recent call. lastN is used to store the argument received in
the most recent call. Clearly this procedure is OP, and mimics the
input-output behavior of a regular factorial procedure that does not cache
any results. 

\subsection{Proposed approach}

%% 1. We are looking for a Hoare logic style approach, for increased
%%    precision. Herein, how to process the recursive calls? One solution is
%%    to make the user guess the mathematical function implemented by the
%%    procedure as well as the invariant on the global variables. Now, the
%%    recursive call can be replaced by these specifications, and the whole
%%    procedure can be checked whether it always returns n!.

%% 2. The approach above would itself be novel. However, one issue is that
%%    theorem provers face difficulty in proving equivalence of complex
%%    formulas. Also, humans face difficulty in inferring meanings of
%%    procedures. We therefore propose a more syntactic approach that is
%%    easier on the theorem prover and on the human. 

Floyd-Hoare logic has been commonly used in previous approaches that try to
tackle verification tasks with good precision. Our proposal is based on
Floyd-Hoare logic as well. In order to verify a recursive procedure
inductively, typically a specification of the procedure would need to be
provided. The first idea for such a specification would be a full
functional specification of the procedure. That is, if someone specifies
that factCache mimics n!, then the verifier could replace Line~10 in the
code with `g = n * (n-1)!'. This, on paper, is sufficient to assert that n!
is returned in Line 12. However, to establish Line~8 also returns n!, an
invariant would need to be provided that describes the possible values of g
before any invocation to the procedure. In our example, a suitable
invariant would be `(g = -1) $\vee$ (g = lastN!)'. The verifier would also
need to verify that at the procedure's exit the invariant is
re-established. Lines 10-12, with the recursive call replaced by (n-1)!,
suffices on paper  to re-establish the invariant.

The candidate approach mentioned above, while being plausible, suffers from
two weaknesses. The first is that a human would need to guess the
mathematical expression returned by the given procedure. This may not be
easy when the procedure is complex. Second, the underlying theorem prover
would need to prove complex arithmetic properties, e.g., that n * (n-1)! is
equal to n!. Complex proofs such as this may be out of bounds for many
existing theorem provers.

Our key insight is to sidestep the challenges mentioned by introducing a
function symbol, say $f$, and replacing the recursive call for the purposes
of verification with this function symbol. Intuitively, $f$ represents the
mathematical function that the given procedure mimics if the procedure is
OP.  In our example, Line~10 would become `g = n * $f$(n-1)'. This step
needs no human involvement. The approach needs an invariant; however, in a
novel manner, we allow the invariant also to refer to $f$. In our example,
a suitable invariant would be `(g = -1) $\vee$ (g = lastN *
$f$(lastN-1))'. This sort of invariant is relatively easy to construct;
e.g., a human could arrive at it just by looking at Line~2 and with a local
reasoning on Lines~10 and~11. Given this invariant, (a) a theorem prover
could infer that the condition in Line~7 implies that Line~8 necessarily
returns n * $f$(n-1). Due to the transformation to Line~10 mentioned above,
(b) the theorem prover can infer that Line~12 also returns n *
$f$(n-1). Note that since these two expressions are syntactically
identical, a theorem prover can easily establish that they are equal in
value.  Finally, since Line~6 is reached under a different condition than
Lines~8 and~12, the verifier has finished establishing that the procedure
always returns the same expression in n for any given value of n.

Similarly, using the modified Line~10 mentioned above and from Line~11, the
prover can re-establish that g is equal to `lastN * $f$(lastN - 1)' when
control reaches Line~12; hence, the given invariant is established to be a
valid invariant.

Note, the effectiveness of the approach depends on the nature of the given
invariant. For instance, if the given invariant was `(g = -1) $\vee$ (g =
lastN!)', which is also technically correct, then the theorem prover may
not be able to establish that Lines~8 and~12 always return the same
expression in n. However, it is our claim that in fact it is the invariant
`(g = -1) $\vee$ (g = lastN * $f$(lastN-1))' that is easier to infer by a
human or by a potential tool, as justified by us two paragraphs above.

\subsection{Salient aspects of our approach}

%% should I talk about why F(2) *3 instead of F(3) ?

The most closely related previous approaches are by Barnett et
al.~\cite{barnett200499,barnett2006allowing},
Naumann~\cite{naumann2007observational}, and~Cok et
al.~\cite{cok2008extensions}.  All these approaches check observational
purity of procedures that maintain mutable global state. However, none of
these approaches use a function symbol in place of recursive calls or
within invariants. Therefore, it is not clear that these approaches can
verify recursive procedures. To
the best of our knowledge ours is the first paper to show that is
feasible to check observational purity of procedures that maintain mutable
global state for optimization purposes and that make use of recursion.

Being able to verify that a procedure is OP has many potential
applications. The most obvious one is that OP procedures can be
memoized. That is, input-output pairs can be recorded in a table, and calls
to the procedure can be elided whenever an argument is seen more than
once. This would not change the semantics of the overall program that calls
the procedure, because the procedure always returns the same value for the
same argument (and mutates only private global variables). Another
application is that if a loop contains a call to an OP procedure, then the
loop can be parallelized (provided the procedure is modified to access and
update its private global variables in a single atomic operation).

In this paper, we do make a number of assumptions. The global variables
that the procedure reads or updates are assumed to be private to it, in the
sense that other code cannot access these variables at all.  For simplicity
of presentation, we assume that loops are not present, and have been
converted to recursion. However, we do not restrict the procedure to use
only tail recursion. We do not as yet address pointers and memory
allocation. Finally, a note about terminology: throughout this paper we
use `procedure' to refer to the code procedure being analyzed, and use
`function' to refer to a mathematical function. 

The rest of this paper is structured as
follows. Section~\ref{sec:background} introduces the core programming
language that we address. Section~\ref{sec:semantics} provides formal
semantics for our language, as well as definitions of invariants and
observational purity. Section~\ref{sec:vcgen} describes our approach
formally.
% Section~\ref{sec:experiments} describes evaluation of our approach on a few realistic examples.
Section~\ref{sec:related} describes related work. The appendix contains some details of the programs
that we used in our evaluations. 

