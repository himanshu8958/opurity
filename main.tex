% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
%% himanshu
\usepackage[title]{appendix}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{syntax}
\usepackage{amssymb}
\newcommand{\foo}{\textit{foo}}
\newcommand{\trace}{\pi}
\newcommand{\inv}{\mathit{inv}}
\newcommand{\history}{\Pi}
\newcommand{\pathCondition}{\mathit{T_{\foo}}}
\newcommand{\OPCheckE}{\mathit{OPCheck \mhyphen existential}}
\newcommand{\OPCheckA}{\mathit{OPCheck \mhyphen pairwise}}
\mathchardef \mhyphen="2D
\newcommand{\mi}[1]{\mathit{#1}}
\newcommand{\retVar}{\textit{retVar}}
\newcommand{\F}{\mathit{F}}
\newcommand{\n}{\textit{n}}
\newcommand{\gstate}{\gamma}
\newcommand{\g}{\textit{g}}
\newcommand{\gout}{\textit{gout}}
\newcommand{\gbef}{\textit{gbef}}
\newcommand{\gaft}{\textit{gaft}}
\newcommand{\satisfies}{\vdash}
\newcommand{\fact}{\mathit{fact}}
\newcommand{\formula}{\mu}
\newcommand{\integer}{\mathbb{N}}
\newcommand{\vci}[2]{\mathit{valid \mhyphen consistent \mhyphen
    invariant(#1, #2)}}
\newcommand{\atEntry}[1]{\mathit{at \mhyphen entry(#1)}}
\newcommand{\beforeCall}[1]{\mathit{before \mhyphen call(#1)}}
\newcommand{\return}[1]{\mathit{return(#1)}}
\newcommand{\atEnd}[1]{\mathit{at \mhyphen end(#1)}}
\newcommand{\tSegment}{\tau}
\newcommand{\param}[1]{\mathit{argument(#1)}}
\newcommand{\segDepth}[2]{\mathit{segment \mhyphen depth(#1, #2)}} %trace, segment
\newcommand{\subTrace}{\pi_{sub}}
\newcommand{\segment}[2]{\mathit{segment(#1, #2)}} %trace, N
\newcommand{\pairFormula}{\mathit{f_{pairwise}}}
\newcommand{\depth}[1]{\mathit{depth(#1)}}
\newcommand{\level}[1]{\mathit{level(#1)}}
\newcommand{\state}{\sigma}
\newcommand{\afterCall}[1]{\mathit{after \mhyphen call(#1)}} 

\lstdefinestyle{mystyle}{
  basicstyle=\footnotesize, 
  %% breakatwhitespace=false,         
  %% breaklines=true,                 
  captionpos=b,
  %% keepspaces=true,         
  numbers=left,
  numbersep=6pt,                  
  %% showspaces=false,                
  %% showstringspaces=false,
  %% showtabs=false,
  morekeywords={if, for, else,
  procedure,modifies, var, returns, int, call, assume},
  %% tabsize=2
}
\lstset{
  %% basicstyle=\itshape,
  style = mystyle,
  xleftmargin=3em,
  %% literate={\alt}{;}{1}
  %% basicstyle=\footnotesize,
  numberstyle=\tiny,
  breaklines=true,
  escapeinside={\%*}{*)}
}

%
\begin{document}
%
\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Hamiltonian Mechanics} % additional mark in the TOC
%
%% \chapter*{Preface}
%% %
%% This textbook is intended for use by students of physics, physical
%% chemistry, and theoretical chemistry. The reader is presumed to have a
%% basic knowledge of atomic and quantum physics at the level provided, for
%% example, by the first few chapters in our book {\it The Physics of Atoms
%% and Quanta}. The student of physics will find here material which should
%% be included in the basic education of every physicist. This book should
%% furthermore allow students to acquire an appreciation of the breadth and
%% variety within the field of molecular physics and its future as a
%% fascinating area of research.

%% For the student of chemistry, the concepts introduced in this book will
%% provide a theoretical framework for that entire field of study. With the
%% help of these concepts, it is at least in principle possible to reduce
%% the enormous body of empirical chemical knowledge to a few basic
%% principles: those of quantum mechanics. In addition, modern physical
%% methods whose fundamentals are introduced here are becoming increasingly
%% important in chemistry and now represent indispensable tools for the
%% chemist. As examples, we might mention the structural analysis of
%% complex organic compounds, spectroscopic investigation of very rapid
%% reaction processes or, as a practical application, the remote detection
%% of pollutants in the air.

%% \vspace{1cm}
%% \begin{flushright}\noindent
%% April 1995\hfill Walter Olthoff\\
%% Program Chair\\
%% ECOOP'95
%% \end{flushright}
%% %
%% \chapter*{Organization}
%% ECOOP'95 is organized by the department of Computer Science, Univeristy
%% of \AA rhus and AITO (association Internationa pour les Technologie
%% Object) in cooperation with ACM/SIGPLAN.
%% %
%% \section*{Executive Commitee}
%% \begin{tabular}{@{}p{5cm}@{}p{7.2cm}@{}}
%% Conference Chair:&Ole Lehrmann Madsen (\AA rhus University, DK)\\
%% Program Chair:   &Walter Olthoff (DFKI GmbH, Germany)\\
%% Organizing Chair:&J\o rgen Lindskov Knudsen (\AA rhus University, DK)\\
%% Tutorials:&Birger M\o ller-Pedersen\hfil\break
%% (Norwegian Computing Center, Norway)\\
%% Workshops:&Eric Jul (University of Kopenhagen, Denmark)\\
%% Panels:&Boris Magnusson (Lund University, Sweden)\\
%% Exhibition:&Elmer Sandvad (\AA rhus University, DK)\\
%% Demonstrations:&Kurt N\o rdmark (\AA rhus University, DK)
%% \end{tabular}
%% %
%% \section*{Program Commitee}
%% \begin{tabular}{@{}p{5cm}@{}p{7.2cm}@{}}
%% Conference Chair:&Ole Lehrmann Madsen (\AA rhus University, DK)\\
%% Program Chair:   &Walter Olthoff (DFKI GmbH, Germany)\\
%% Organizing Chair:&J\o rgen Lindskov Knudsen (\AA rhus University, DK)\\
%% Tutorials:&Birger M\o ller-Pedersen\hfil\break
%% (Norwegian Computing Center, Norway)\\
%% Workshops:&Eric Jul (University of Kopenhagen, Denmark)\\
%% Panels:&Boris Magnusson (Lund University, Sweden)\\
%% Exhibition:&Elmer Sandvad (\AA rhus University, DK)\\
%% Demonstrations:&Kurt N\o rdmark (\AA rhus University, DK)
%% \end{tabular}
%% %
%% \begin{multicols}{3}[\section*{Referees}]
%% V.~Andreev\\
%% B\"arwolff\\
%% E.~Barrelet\\
%% H.P.~Beck\\
%% G.~Bernardi\\
%% E.~Binder\\
%% P.C.~Bosetti\\
%% Braunschweig\\
%% F.W.~B\"usser\\
%% T.~Carli\\
%% A.B.~Clegg\\
%% G.~Cozzika\\
%% S.~Dagoret\\
%% Del~Buono\\
%% P.~Dingus\\
%% H.~Duhm\\
%% J.~Ebert\\
%% S.~Eichenberger\\
%% R.J.~Ellison\\
%% Feltesse\\
%% W.~Flauger\\
%% A.~Fomenko\\
%% G.~Franke\\
%% J.~Garvey\\
%% M.~Gennis\\
%% L.~Goerlich\\
%% P.~Goritchev\\
%% H.~Greif\\
%% E.M.~Hanlon\\
%% R.~Haydar\\
%% R.C.W.~Henderso\\
%% P.~Hill\\
%% H.~Hufnagel\\
%% A.~Jacholkowska\\
%% Johannsen\\
%% S.~Kasarian\\
%% I.R.~Kenyon\\
%% C.~Kleinwort\\
%% T.~K\"ohler\\
%% S.D.~Kolya\\
%% P.~Kostka\\
%% U.~Kr\"uger\\
%% J.~Kurzh\"ofer\\
%% M.P.J.~Landon\\
%% A.~Lebedev\\
%% Ch.~Ley\\
%% F.~Linsel\\
%% H.~Lohmand\\
%% Martin\\
%% S.~Masson\\
%% K.~Meier\\
%% C.A.~Meyer\\
%% S.~Mikocki\\
%% J.V.~Morris\\
%% B.~Naroska\\
%% Nguyen\\
%% U.~Obrock\\
%% G.D.~Patel\\
%% Ch.~Pichler\\
%% S.~Prell\\
%% F.~Raupach\\
%% V.~Riech\\
%% P.~Robmann\\
%% N.~Sahlmann\\
%% P.~Schleper\\
%% Sch\"oning\\
%% B.~Schwab\\
%% A.~Semenov\\
%% G.~Siegmon\\
%% J.R.~Smith\\
%% M.~Steenbock\\
%% U.~Straumann\\
%% C.~Thiebaux\\
%% P.~Van~Esch\\
%% from Yerevan Ph\\
%% L.R.~West\\
%% G.-G.~Winter\\
%% T.P.~Yiou\\
%% M.~Zimmer\end{multicols}
%% %
%% \section*{Sponsoring Institutions}
%% %
%% Bernauer-Budiman Inc., Reading, Mass.\\
%% The Hofmann-International Company, San Louis Obispo, Cal.\\
%% Kramer Industries, Heidelberg, Germany
%% %
%% \tableofcontents
%% %
\mainmatter              % start of the contributions
%
\title{Checking Observational Purity of Procedures}
%
\titlerunning{Hamiltonian Mechanics}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
%% \author{Ivar Ekeland\inst{1}\orcidID{0000-1111-2222-3333} \and
%% Roger~Temam\inst{2}\orcidID{1111-2222-3333-4444} \and
%% Jeffrey~Dean\orcidID{2222-3333-4444-5555} \and
%% David~Grove\orcidID{3333-4444-5555-6666} \and
%% Craig~Chambers\orcidID{4444-5555-6666-7777} \and
%% Kim~B.~Bruce\orcidID{5555-6666-7777-8888} \and
%% Elsa~Bertino\orcidID{6666-7777-8888-9999}}
%% %
%% \authorrunning{Ivar Ekeland et al.} % abbreviated author list (for running head)
%% %
%% %%%% list of authors for the TOC (use if author list has to be modified)
%% \tocauthor{Ivar Ekeland, Roger Temam, Jeffrey Dean, David Grove,
%% Craig Chambers, Kim B. Bruce, and Elisa Bertino}
%% %
%% \institute{Princeton University, Princeton NJ 08544, USA,\\
%% \email{I.Ekeland@princeton.edu},\\ WWW home page:
%% \texttt{http://users/\homedir iekeland/web/welcome.html}
%% \and
%% Universit\'{e} de Paris-Sud,
%% Laboratoire d'Analyse Num\'{e}rique, B\^{a}timent 425,\\
%% F-91405 Orsay Cedex, France}

\maketitle              % typeset the title of the contribution

\begin{abstract}
%% The abstract should summarize the contents of the paper
%% using at least 70 and at most 150 words. It will be set in 9-point
%% font size and be inset 1.0 cm from the right and left margins.
%% There will be two blank lines before and after the Abstract. \dots

  %% Observational purity checks if a given procedure is a pure function
  %% of it's arguments modulo the side effects.
  %% (option 1)\\
  %% A procedure that is a pure function of its arguments modulo side
  %% effect to the global state is Observationally pure (OP). We present
  %% a pair of static analysis approaches that entail OPness. In-order to
  %% statically check OPness, we need an invariant on the global states
  %% at the boundaries of the procedure. Allowing the invariant to be
  %% defined in terms of the given procedure (assuming it is OP)
  %% simplifies invariant construction. This also allows us to
  %% automatically check OPness for recursive procedures. \dots\\

  %% (option 2)\\
  
  %% A specification language that includes procedure calls greatly
  %% improves the ease of expression. Java modelling language (JML)
  %% currently allows only pure procedures (side effect free) to be used
  %% in the specifications. This is overly restrictive, as the procedure
  %% might have benign side effects, which are not observable to other
  %% procedures (or itself). Observationally pure procedures may read or
  %% write to global variables, but their input-output behaviour is
  %% independent of the global state.

  Specification languages for imperative languages such as Spec\#,
  JML, Eiffel allow procedure calls in the contracts of the
  procedure. In order to tame interference between the runtime checking
  of the specifications and the implementation, a notion of purity is
  needed. Strong purity allows no side effects whereas weak purity
  allows no side effects on pre-existing objects. Another way to look
  at purity is as follows : does the side-effect affect the
  input-output behaviour of the given procedure or other procedures?
  If not, such a procedure is called \textit{observationally
    Pure}. Specifications in JML allow only strongly pure procedures
  which is overly restrictive. A procedure may have benign side
  effects which do not affect the input-output behaviour of the
  procedure; thus, there is a need for observational purity.

  We formalize a notion of observational purity and a conditional
  invariant which is defined only if the procedure is observationally
  pure.  We present two sound static analysis approaches that can
  check observational purity of a procedure. These techniques do not
  require any user annotations for array-free programs and are
  applicable to recursive procedures, which is beyond the scope of
  current literature.

  \keywords{specification languages, observational purity, pure procedure,
  programming by contract, static analysis}
\end{abstract}

\section{Introduction}
Verifying functional properties of procedures is a hard task.
Formalizing such properties of a procedure requires deep understanding
of the procedure's (expected) functionality.  In this paper, we talk
about a general property that is a necessary condition for the
correctness of many procedures. If the return value from a procedure
is dependent only on the formal arguments even if the procedure
reads/writes to global variables, the given procedure is considered as
\textit{Observationally pure(OP)}.  If a procedure $\foo$ is
observationally pure, then there exists a mathematical function $\F$
such that $\F$ mimics the input-output behaviour of $\foo$, and both
$\foo$ and $\F$ have the same signature.  Thus, the input-output
behaviour of procedure $\foo$ is independent of the value of the
global variables.  This has many applications. For instance,
non-optimal implementations of dynamic programming algorithms that do
not use memoization can be refactored to use memoization
automatically.  Checking whether a given procedure is OP is
undecidable. In this paper, we propose a pair of static analysis
techniques to check OPness that are proved to be sound i.e they give a
valid answer on termination.

All arithmetic and logical operators are mathematical-functions, and
functional composition is closed under the set of functions
(hereonwards, we will refer to mathematical-functions as functions and
by procedure we mean a procedure in an imperative programming
language).  In the absence of global variables, all procedures are a
function of their formal arguments. This paper focuses on checking if
a procedure that reads and writes global variables is OP.

\begin{lstlisting}[language=c, caption= {Procedure `factorial' :
      returns factorial of `n' and memoizes result for argument value
      `3'.}, label=lst:factorialSimple]
int g = -1;
int factorial( int n) {
  if(n <= 1) {
    return 1;
  } else if(g == -1 && n == 3) {
    g = 3 * factorial( 2 );
    return g;
  } else if(g != -1 && n == 3) {
    return g;
  } else {
    return n * factorial( n - 1 );
  }
}
\end{lstlisting}

Procedure `factorial' in Listing~\ref{lst:factorialSimple} mimics the
function $\lambda n. n!$. Procedure factorial caches results using the
global variable `g', for parameter value `n = 3'. Initially, `g = -1',
where `-1' represents the un-initialized value. At line 6, global
variable `g' is set to 3! iff `g' had the value `-1' at line
5. Next, line 9 is reached iff global variable `g' is not `-1',
implying that procedure `factorial' has been called with `n = 3'
previously. At line 9, the procedure correctly returns the value
`3!'. Other than this caching behaviour for `n=3' this is similar to
the standard implementation for `factorial'.


OPness is a property of a procedure and the set of \textit{reachable
  global states} where \textit{reachable global states} represents the
set of global states that are encountered at the boundaries of the procedure,
in a sequence of executions
of the given procedure  and a \textit{global state} is an assignment to
the global variables. Procedure `factorial' in
Listing~\ref{lst:factorialSimple} is OP if the global state is
restricted to the set $\{\{g = -1\}, \{g = 3!\}\}$, it mimics the
function $\lambda n.n!$. But for the global states $\{\{g = 1\}, \{g =
3!\}\}$, procedure `factorial' is not a mathematical function. For
argument value `$n = 3$' it may return `1' or `3!'.  We assume that
the set of reachable global states can be represented in the
underlying logic and we refer to it as \textit{invariant}.  The global
states reachable at any boundary, of any procedure call in a sequence
of procedure calls must satisfy the invariant.

To check if a given procedure is OP, we ensure that for all reachable
global states, for each argument value, there is a unique result. Now,
this can be modelled using standard pre and post conditions. The pre
condition holds at the beginning of the procedure and the post
condition holds at its end. Both the pre condition and the post
condition can be substituted by the invariant $\inv$ ( in-order to
verify the invariant). This however does not constrain the return value of the
procedure. But, the return value from a recursive call may flow
into a global variable. Thus, the return from the procedure must be
modelled in the post condition; to re-establish $\inv$.  For procedure
`factorial' in Listing~\ref{lst:factorialSimple} we can use the
invariant `$\inv : g = -1 \vee g = 6$' and the function `factorial'
can be modelled as `$ f := k \leq 1 \implies \fact[k] = 1 \wedge k >1
\implies \fact[k] = \fact[k-1]*k$'. Thus, the pre-condition is
`$\inv$' and the post-condition is `$\inv \wedge f \wedge \retVar =
fact[n]$' where $\retVar$ is the return variable. This post-condition
will not only check the validity of the invariant but also that the
given procedure is OP, as the return value is constrained to be
equivalent to `$fact[n]$'.

The above mentioned idea is sound, modulo usability. The issues are:
(a) theorem provers often fail to prove such assertions (as is the
case for the above mentioned example) (b) describing the procedure in
logic takes considerable effort.  Instead of formalizing the function
for the given procedure, why not equate the result from the procedure
to that of an uninterpreted function symbol? This function symbol can
also be used to represent the return value from the inner procedure
calls. Next, we ask the question whether an assignment for the
function symbol exists? If yes, then the procedure is OP, otherwise it
is not OP.  This is our existential approach.

Abstracting using function symbols goes a long way. It helps in
representing the post-condition in a simpler manner and also it aids
in describing the invariant. For procedure `factorial', we can use
the invariant `$\inv_{\F}:=g = -1 \vee g = \F(2) * 3$'. The symbol
`$\F(2)$' in the invariant represents the return value from the
procedure `factorial' for argument `$n = 2$', assuming procedure
`factorial' is a mathematical function. Note that the invariant used
here is valid if the given procedure is OP, otherwise it is not well
defined.

%% should I talk about why F(2) *3 instead of F(3) ?

OPness can also be checked by comparing a procedure to itself. We
represent two instances of a procedure in some underlying logic, and
then ask the question that do the two instances of the given procedure
mimic each other, for all argument values, and all states satisfying
the invariant? If yes, then we show that the given procedure is
OP. Otherwise, we construct a witness to the impurity of the given
procedure. We can construct a pair of traces, such that both begin in
a global state in the invariant, the same argument value but return
different results. We call this the `impurity witness approach'.
This approach also makes use of  invariant with uninterpreted function
symbols like the previous approach.

Since observational purity is a property on the return values from a
procedure, this problem is closely related with the termination of the
given procedure. In Section~\ref{sec:background}, we define OPness in
a way such that non-termination does not cause non-OPness. OP is
violated if for a given invariant on the reachable global states, for
a given argument value there is a non-unique return value. And in-case
of non-termination there isn't a return value. Hence, a
non-terminating procedure is OP.

One direct application of this work is automatic memoization. Dynamic
programming algorithms (such as procedure `factorial' in
Listing~\ref{lst:factorialSimple}) use memoization to store
pre-computed solutions to the sub-problem so that the results can be
looked-up when needed, thus trading memory for compute time. Our
technique can check if it is safe to memoize the results produced by a
procedure. By safety, we refer to preserving the input-output
behaviour. We propose two static analysis approaches to check this
problem. One interesting thing about our approach is that the user
need not mention a (the) mathematical function that the procedure is
supposed to mimic. Also, using a function symbol allows generating the
invariant automatically.

\section{Background} \label{sec:background}

\subsection{Programming Language}
We make the following restrictions on the structure of the program to
simplify the analysis without loss of generality.

\begin{itemize}
\item The given procedure (`\foo') has a single argument i.e `\n'. And
  `\n' is never written inside `\foo'.
\item Procedure `\foo' has a single global variable, named `\g'.
\item Return statement is absent from our programming language. Instead,
  we have a special variable `\retVar', which is assigned the return
  value.
\item We analyze a single procedure in isolation and we assume that no
  other procedure writes to the global variables accessed by procedure
  `\foo'. In-case of multiple procedures, the invariant has multiple
  function symbols, one for each procedure. 
\item All variable are defined before use, except global variables.
\item All loops in procedure `\foo' are substituted with 
  recursive procedures.
\item Variable assigned the return value in a procedure call
  statement is always a local variable.
\item There is at max one procedure call statement in every straight line
  execution of `\foo' from the beginning until it's end.
  \end{itemize}
%% Note : all of the above mentioned restrictions can be omitted. They
%% are for convenience.

In Figure~\ref{fig:grammar}, we present the grammar for the
programming language which we have assumed for our static analysis
approaches.  Most of the statements are standard statements borrowed
from imperative languages. The rest of them are explained next. The
statement `havoc x' assigns any value from the domain of the variable
`x' to variable `x'.
%% to variable `x' from the declared domain of `x'
%% And the statement `assume x' allows the execution of the program to
%% proceed if the predicate `x' holds at the program point, otherwise it
%% halts the execution.

\begin{figure}[hb!]
  %% \includegraphics[trim={0 5cm  3cm 0}, width=6cm]{grammar.eps}
  \begin{grammar}
    <statement> ::= <ident> = <constant>
    \alt <ident> = <logical-expr>
    \alt <ident> = <arithmetic-expr>
    \alt <statement>; <statement>
    \alt if<logical-expr> then <statement> else <statement>
    %% \alt while<logical-expr> do <statement>
    %% \alt <ident> = foo(<params-list>)
    %% \alt assume(<logical-expr>)
    \alt <ident> = \foo(<ident>)
    \alt havoc(<ident>)
    %% \alt <ident>[<ident>] = <ident>
    %% \alt <ident> = <ident>[<ident>]

    %% <params-list> ::= <params-list> , <ident>
    %% \alt <ident>

    <arithmetic-expr> ::= <ident> "+" <ident>
    \alt <ident> "-" <ident>
    \alt <ident> "/" <ident>
    \alt <ident> "*" <ident>
    \alt <ident> "\%" <ident>
 
    <logical-expr> ::= <ident> "<" <ident>
    \alt <ident> ">" <ident>
    \alt <ident> "==" <ident>
    \alt <ident> $\leq$ <ident>
    \alt <ident> $\geq$ <ident>
    \alt <logical-expr> $\wedge$ <logical-expr>
    \alt <logical-expr> $\vee$ <logical-expr>
    \alt $\neg$<logical-expr>
    \alt true
    \alt false

    <ident> ::= <local-ident>
    \alt <global-ident>
    
    <procedure> ::= procedure \foo ($\n$) {<statement>;}
  \end{grammar}
  \caption{Grammar for our programming language}
  \label{fig:grammar}
\end{figure}

\subsection{Our intermediate representation}\label{sec:intermediate}
We transform the given procedure into the following representation
in-order to represent it in logic. For example procedure `factorial'
in Listing~\ref{lst:factorialTransformed}, is the transformed version
of procedure `factorial' in Listing~\ref{lst:factorialSimple}.

Our analysis expects the following :
\begin{enumerate}
\item Expressions do not have procedure call statements as
  sub-expressions. 
\item Procedure calls are approximated using function symbols. The
  statement `x = \foo(y)' is replaced with `x = $\F$(y)'. Since
  procedure calls may modify global variables, we add the statement
  `havoc g' for each global variable `g' accessible from the
  procedure.
\item The input procedure has `m' procedure calls.
\item Next, the procedure must have extra variables to store the value
  of global variables at procedure boundaries.  Before the
  $\mathit{i^{th}}$ procedure call, we add the statement `gbef$_i$ =
  g' and after it we add `gaft$_i$ = g'. Similarly, we add the
  statement `gout = g' after the assignment to the variable `\retVar'.
\item The procedure should be in static single assignment (SSA)
  form. The procedure should be converted to SSA after the above
  mentioned points have been satisfied.
\end{enumerate}

\begin{lstlisting}[language=c, caption= {Procedure `factorial' from
      Listing~\ref{lst:factorialSimple} converted to the form our
      approach expects. We refer to this procedure as `transformed
      factorial'.}, label=lst:factorialTransformed]
int g = -1;
int transformedFactorial( int n) {
  if(n <= 1) {
    retVar = 1;
    gout = g;
  } else if(g == -1 && n == 19) {
    gbef1 = g;
    temp1 = F(18);  // temp1 = factorial(18)
    havoc(g1);
    gaft1 = g1;
    g2 = 19 * temp1;
    retVar = g2;
    gout = g2;
  } else if(g != -1 && n == 19) {
    retVar = g;
    gout = g;
  } else {
    gbef2 = g;
    temp2 = F( n - 1 );  //temp2 = factorial(n-1)
    havoc(g1);    
    gaft2 = g1;
    retVar = n * temp2;
    gout = g1;
  }
}
\end{lstlisting}

%% In procedure `transformedFactorial'
%% Listing~\ref{lst:factorialTransformed}, in comparison to procedure
%% `factorial' in Listing~\ref{lst:factorialSimple}, the return statement
%% (line 4) is replaced by an assignment to variable `\retVar' (line
%% 4). After line 5 of `transformed factorial', an extra variable `gout'
%% is assigned the value of global variable `g' (value of `g' at end of
%% program).  Similarly, variable `gbef1' (line 7, `transformed
%% factorial') is added to capture the value of the global variable
%% before the procedure call (a program boundary), and variable `gaft1'
%% is inserted at line 11 to capture the value of `g' after the procedure
%% call. Also, havoc statements at line 8, 20 and 9, 21 over-approximate
%% the return from the procedure call statement and updates to the global
%% variable respectively. The procedure call statement is substituted
%% with function symbols in line 10 and 22, accounting the given
%% procedure as a function.

Now we compare `transformed factorial' and procedure `factorial' from
Listings~\ref{lst:factorialTransformed} and \ref{lst:factorialSimple}
respectively. The return statement (line 4) in procedure `factorial'
is replaced by assignment to variable `\retVar' (line 4). Also, we
have a added an assignment statement (line 5) in `transformed
factorial', that defines variable `gout' in-order to store the value
of variable `g' at the procedure boundary. Similarly, variable `gbef1'
(line 7) is added in `transformed factorial' to capture the value of
the global variable before the procedure call and assignment to
variable `gaft1' is inserted at line 10 to capture the value of `g'
after the procedure call. Also, havoc statements at lines 9 and 20
over-approximate any side effects to the global variables. And in
lines 8 and 19, the procedure call statements are substituted for
function symbols.

\subsection{Path Condition}
For our analysis we represent the given procedure in logic, such that
it captures the value of the argument, the return value and the values
of the global variables at the boundaries. We track the values of the
global variables using extra variables as explained in
Section~\ref{sec:intermediate}.

\begin{figure}
  \begin{align*}
    \pathCondition :=
    &(n \leq 1 \wedge retVar = 1 \wedge gout = g) \vee \\
    &(n > 1 \wedge g = -1 = gbef \wedge n = 19 \wedge temp1 = \F(18) \\
    \;&\wedge gaft1 = g1 \wedge g2 = 19 * temp1
    \wedge retVar = g2) \vee\\
    &(n > 1 \wedge \neg( g = -1 \wedge n = 19) \wedge g \neq -1
    \wedge n = 19 \wedge retVar = g = gout) \vee\\
    &(n > 1 \wedge n \neq 19 \wedge gbef2 = g \wedge temp2 = \F( n
    - 1) \wedge gaft2 = g1\\
    &\wedge retVar = n * temp2 \wedge gout = g1)\\
  \end{align*}
  \caption{Formula representing procedure `transformed factorial' in
    Listing~\ref{lst:factorialTransformed} (assuming that function
    $\F$ is equivalent to procedure `factorial').}
  \label{fig:pathCondition}
\end{figure}

For example, the procedure `transformed factorial' in
Listing~\ref{lst:factorialTransformed} is expressed in logic as shown
in Figure~\ref{fig:pathCondition}. Each disjunct in
Figure~\ref{fig:pathCondition} represents a straight-line execution of
procedure `factorial' (from beginning, until end) . For instance, $(n
<= 1 \wedge retVar = 1 \wedge gout = g)$ represents the case where $n
\leq 1$. Here onwards, we will only use this formula, $\pathCondition$
to describe our analysis.



Representation of a program in logic is straight forward once it is
converted to our intermediate representation in
Section~\ref{sec:intermediate}. All the standard imperative statements
become conjuncts in the formula. `havoc' statements are omitted.
`assume x' are replaced with a conjunct `x' in the formula.

\section{Invariant}

To introduce the definition of an invariant we first define
\textit{trace} and \textit{history}.

\begin{definition}[trace]
  A trace $\trace$ is a complete execution of the procedure starting
  from a given global state and a tuple of formal arguments. A trace
  upon completion gives an end state and a return value.\\ 
 Traces may have sub-traces, which by definition are traces
  (recursive calls).
\end{definition}

\begin{definition}[history]
  A history $\history$ is a sequence of consecutive traces, with the
  first trace starting from a given global state, and each subsequent
  trace begins in the state in which the previous trace ends.
\end{definition}

\begin{definition}[invariant]
  An invariant $\inv$ represents the set of global states at the
  boundaries of a procedure. $\inv$ is a formula, with 
  global variables accessed by the given procedure and a uninterpreted
  function symbol $\F$ as the set of free variables.
  %% If a procedure begins in state that satisfies $\inv$, then it ends
  %% in a state that satisfies $\inv$.
  The uninterpreted function symbol $\F$ is a placeholder for the
  mathematical function equivalent to the given procedure.
  

  %% An invariant $\inv$ is a formula with an uniterpreted function
  %% symbol $\F$ and the global variables accessed by the given procedure
  %% as free variables.
  
  %% Similar to pre-condition and post-conditions clauses, $\inv$ holds before a
  %% procedure call and it is assumed after the procedure call.
  
  %% %% It represents the set of global states that may
  %% %% arise before and after each procedure call of the given procedure in
  %% %% a set of histories. Thus, if a procedure begins in a global state
  %% %% that satisfies invariant $\inv$ then the state before the procedure
  %% %% call also satisfies $\inv$.
  %% %% Also, assuming the inner recursive call
  %% %% ends in a state statisfying $\inv$, the global state at the end of
  %% %% the procedure also satisfies $\inv$.
  %% %% it also ends in a global state that
  %% %% satisfies $\inv$.
  %% Some variables may be defined in terms of a
  %% function symbol $\F$, which in turn refers to the mathematical
  %% function that is equivalent to the given procedure.
  
\end{definition}

An invariant $\inv$ is assumed at the beginning of the procedure and
asserted at the end. Also, asserted before a procedure call and
assumed after the procedure call. This treatment of the invariant
$\inv$ is very similar to how pre-conditions and post-conditions are
handled for recursive procedures. But, the invariant used here assumes
that the given procedure is observationally pure, invariant has the
free variable $\F$ which is also used to abstract over procedure
calls. The invariant is defined only if the given procedure is
observationally pure otherwise it is undefined.

Let $\gstate$ be a global state, and $\F'$ be a function, and $\inv$
be a invariant. If we substitute $\gstate$ for $g$ and $\F'$ for $\F$
in $\inv$ and it is true, then we say that $(\gstate, \F')$ satisfies
$\inv$, which is denoted as $\inv[\gstate/g, \F'/\F] \implies
(\gstate, \F') \satisfies \inv$. For instance let $\inv := g = -1 \vee
g = \F(18) * 3$ then $(3!, \lambda n. n!) \satisfies \inv$.

\section{Observational purity}
\begin{definition}[observational purity(invariant $\inv$)]
 A given set of procedures are observationally pure if in each history
 starting from a state in invariant $\inv$, all traces of each
 procedure with the same argument value return the same result.
\end{definition}

\begin{lstlisting}[caption={Procedure `remember' : always returns the
      argument from its first call}, label=lst:remember]
int g = 0;
int init = 0;
int remember( int n) {
  if(init == 0){
    init = 1;
    g = n;
  }
  return g;
}
\end{lstlisting}

In a history, if all traces return the same result for an
argument value, then we can find a function $\F$ that respects the
given procedure. But, the given procedure may mimic a different
function $\F'$ in another history. If the invariant is a set of concrete
states then there is a unique function that is equivalent to the given
procedure. But, our invariant allows function symbols. This allows an
OP procedure to mimic different functions in different histories.
%% The invariant we use allows multiple functions to
%% be equivalent to the given procedure.
For instance, procedure `remember' in Listing~\ref{lst:remember}
mimics a constant function for $\inv := g=0 \wedge init=0 \vee g= \F()
\wedge init=1$. Whereas, for the invariant $\inv := g=0 \wedge init=0
\vee g=2 \wedge init=1$; the procedure mimics the function $\lambda
n.2$.

\section{Existential approach}\label{sec:existential}

\begin{figure}[htp]
  \begin{algorithm}[H]
    \begin{align*}
      \OPCheckE
       & \mi{(\inv :
        invariant, \pathCondition : path \; condition)} \equiv \\
      &\inv \wedge \inv[\gaft_1/\g] \wedge \inv[\gaft_2/\g] \wedge
      \cdots \inv[\gaft_m/\g] \\
      &\wedge \pathCondition \implies ( \retVar = \F(\n)\\
            & \wedge \inv[\gout/\g] \wedge  \inv[\gbef_1/\g] \wedge
      \inv[\gbef_2/\g] \wedge \cdots inv[\gbef_m/\g]) \\
    \end{align*}
    \caption{Existential check : produces a formula whose
      satisfiability implies the given procedure is observationally
      pure} 
    \label{algo:someOPcheckCombined}
  \end{algorithm}  
\end{figure}

The existential approach in Algorithm~\ref{algo:someOPcheckCombined}
encodes a formula $\formula_e$. In formula $\formula_e$, the invariant
is assumed at the beginning of the procedure, and after each procedure
call ( $m$ procedure calls in total).  We abstract all the recursive
procedure calls in the original procedure using function symbol $\F$
in $\pathCondition$.  Next, the return value is constrained to be
equivalent to $\F(n)$, where `n' is the parameter value. Formula
$\formula_e$ has a single free variable $\F$, and it is constrained to
respect the given procedure, for all values of the parameter `n' and
all values of the global variable `g'. Thus, if $\formula_e$ is SAT,
it implies that there exists a function which mimics the given
procedure. 

The check encoded in Figure~\ref{algo:someOPcheckCombined} cannot be
expressed using standard requires and ensures statements (to the best
of our knowledge). In the intra-procedural analysis, the validity of
the ensures statements is verified. We ensure that if the procedure
has an `ensures x' statement, then the state $\neg$x is not reachable
at the program point.  In our analysis, we check a weaker
condition. We check if $\retVar = \F(n)$ is satisfiable. But this
suffices for our analysis.

\subsection{Proof of correctness}
\begin{definition}[local state]
  A local state is a mapping from the local variables to their
  values. 
\end{definition}

\begin{definition}[global state]
  A global state $\gstate$ is a mapping from the global variables to
  their values.
\end{definition}

\begin{definition}[state]
  A state is a pair consisting of a global state and a stack of local
  states. We use the symbol $\state$ to denote the state of a program
  at a program point.
\end{definition}

\begin{definition}[argument(trace $\rightarrow$ value)]
  $\param{\trace}$ denotes the mapping of the argument `$\n$' to its
  value in the beginning of $\trace$.
\end{definition}

\begin{definition}[returns(trace $\rightarrow$ value)]
  $\return{\trace}$ denotes the mapping of the variable\\ $\retVar$ to
  its value at the end of trace $\trace$.
\end{definition}

\begin{definition}[at-entry(history/trace/trace-segment)  $\rightarrow$
    value] 
  %% $\atEntry{x}$ denotes $\gstate$, such that $\gstate$ is the global
  %% state at the starting point of $x$ where $x$ is a history, trace or
  %% trace segment.
  $\\\atEntry{x}$ denotes the value of global variable $\g$ at the
  starting point of $x$ where $x$ is a history, trace or trace
  segment. 
\end{definition}

\begin{definition}[at-end(history/trace/trace-segment) $\rightarrow$
    value]
  $\atEnd{x}$ denotes the\\ value of the global variable $\g$ at the end
  of $x$, where $x$ is a history, trace or a trace segment. 
%%   $\atEnd{x}$ denotes $\gstate$, such that $\gstate$ is the global
%%   state at the end of $x$ where $x$ is a history, trace or trace
%%   segment.
%% \e
\end{definition}

\begin{definition}[before-call(history/trace/trace-segment)
    $\rightarrow$ value]
  $\beforeCall{x}$ denotes the value of global variable $\g$ before
  the first procedure call statement in $x$, where $x$ is a history,
  trace or a trace segment. $\beforeCall{x}$ is undefined if $x$ does
  not have a procedure call statement.
  %% $\beforeCall{x}$ denotes $\gstate$, such that $\gstate$ is the
  %% global state before the first procedure call statement in $x$, where
  %% $x$ is a history, trace or trace segment. $\beforeCall{x}$ is
  %% undefined if $x$ does not have a procedure call statement.
\end{definition}

\begin{definition}[after-call(history/trace/trace-segment)
    $\rightarrow$ value]
  $\afterCall{x}$ denotes the value of the global variable $\g$ after
  the the first procedure call statement in $x$, where $x$ is a
  history or a trace. $\afterCall{x}$ is undefined if $x$ does not
  have a procedure call.
  %% $\afterCall{x}$ denotes $\gstate$, such that $\gstate$ is the state
  %% in $x$ after the first procedure call statement, where $x$ is a
  %% history or a trace. $\afterCall{x}$ is undefined if $x$ does not
  %% have a procedure call.
\end{definition}

\begin{definition}[sub-trace]
  A sub-trace $\subTrace$ is a trace such that there exists a trace
  $\trace$ such that $\beforeCall{\trace} = \atEntry{\subTrace}$,
  $\afterCall{\trace} = \atEnd{\subTrace}$, trace $\trace$ has a
  procedure call statement $\foo(k)$ and $k = \param{\subTrace}$.
\end{definition}

\begin{definition}[trace-segment]
   trace segment $\tSegment$ is a maximal continuous sub-sequence of a
   trace such that it does not span a procedure entry or exit.
\end{definition}

\begin{definition}[prefix\; trace\; segment]
  A prefix trace segment is a trace segment that begins at the entry
  of procedure `\foo' and ends at the point just before a recursive
  call.
\end{definition}

\begin{definition}[suffix\; trace\; segment]
  A prefix trace segment is a trace segment just after a recursive
  call and ends at the end of the procedure `\foo'.
\end{definition}

\begin{definition}[whole\; trace\; segment]
  A trace-segment that is a complete trace that does not have a
  recursive call.
\end{definition}

\begin{definition}[segment(trace, $\integer$)
    $\rightarrow$ trace segment]
  $\segment{\trace}{n}$ returns the $n^{th}$ trace-segment of trace
  $\trace$. The trace-segments of a trace are ordered in the order of
  execution.
\end{definition}

\begin{definition}[segment-depth(trace segment, trace)$\rightarrow
    \integer$)] Let $\trace$ be trace and $\tSegment$ be a trace
  segment in $\trace$. Let $\tSegment' = \segment{\trace}{1}$.
  $\segDepth{\tSegment}{\trace}$ is the difference in depth of stack
  in $\tSegment$ and $\tSegment'$, plus 1.
\end{definition}


\begin{definition}[valid and consistent invariant( Function,
    Formula)]
  \label{def:validConsistentInvariant}
  $\\\vci{\F}{\inv}$ is a boolean property that is true if for all
  traces and prefix-trace-segments $x$ of procedure `\foo' such that
  $(\atEntry{x}, \F) \satisfies \inv$ the following holds

  \begin{enumerate}
  \item if $x$ is a trace.
    \begin{enumerate}
    \item If $x$ has a recursive call
      \begin{enumerate}
      \item then $(\beforeCall{x}, \F) \satisfies \inv$ and
      \item let $x$ have the procedure call statement, say $y =
        \foo(z)$. Then we change the value of $y$ to $y'$ and the
        value of the global variable $\g$ to $g'$ after the procedure
        call statement such that $y' = \F(z)$ and $(g', \F)
        \satisfies \inv$.
      \end{enumerate}
      Then $\return{x} = \F(\n)$, where $\n$ is the argument to
      trace $x$ and $(\atEnd{x}, \F) \satisfies \inv$.
    \item if $x$ does not have a recursive call
      then $(\atEnd{x}, \F) \satisfies \inv$ and $\return{x} =
      \F(\n)$, where $\n$ is the argument to trace $x$.
    \end{enumerate}
  \item if $x$ is a prefix trace segment.\\
    Then $(\atEnd{x}, \F) \satisfies \inv$.
  \end{enumerate}
\end{definition}

\begin{lemma}\label{lemma:interface}
  If $\OPCheckE\mi{(\inv : invariant, \pathCondition : path \;
    condition)}$ (Algorithm~\ref{algo:someOPcheckCombined}) returns
  formula $\formula$ and $\F'$ be any function such that $\F'
  \satisfies \formula$ then\\ $\vci{\inv}{\F'}$ holds.
\end{lemma}


\begin{lemma} \label{lemma:trace}
Let $\trace$ be any trace, $\inv$ be any formula and $\F$ be any
mathematical function such that $\vci{\F}{\inv}$ and
$(\atEntry{\trace}, \F) \satisfies \inv$ then,\\ $\return{\trace} =
\F(\param{\trace})$ and $(\atEnd{\trace}, \F) \satisfies \inv$.
\end{lemma}

\begin{proof}
  To prove this lemma we will first show that for each transitive sub-trace
  $\subTrace$ of $\trace$, $(\atEntry{\subTrace}, \F) \satisfies
  \inv$. Next, Trace $\trace$ will have an innermost trace (say
  $\subTrace^0$), which by definition cannot have a recursive
  call. Sub-trace $\subTrace^0$ respects function $\F$ because
  $\vci{\F}{\inv}$ holds. Next, we will prove that the sub-trace
  surrounding $\subTrace^0$, say $\subTrace^1$ respects function $\F$
  as $\vci{\F}{\inv}$ holds. Next, the sub-trace surrounding
  $\subTrace^1$. And so on. This way, one by one, starting from the
  inner most sub-trace we prove that each surrounding sub-trace
  respects function $\F$.

  Inductive Hypothesis $P(n)$: Let $\inv$ be a formula, $\F$ be an
  function, $\trace$ and $\subTrace$ be any traces, $\tSegment$ be a
  trace-segment such that $\vci{\F}{\inv}$, $(\atEntry{\trace}, \F)
  \satisfies \inv$, $\tSegment = \segment{\trace}{n}$,
  $(\atEntry{\tSegment}, \F) \satisfies \inv$,\\
  $\segDepth{\tSegment}{\subTrace} = 1$, then $(\atEnd{\tSegment}, \F)
  \satisfies \inv$ and if $\tSegment$ is a suffix-trace-segment or a
  whole-trace-segment then $\return{\subTrace} =
  \F(\param{\trace})$.
  
  Base case : Let $\tSegment = \segment{\trace}{0}$. We have,
  $(\atEntry{\trace}, \F) \satisfies \inv$, thus $(\atEntry{\tSegment},
  \F) \satisfies \inv$ as $\atEntry{\tSegment} =
  \atEntry{\trace}$. $(\atEnd{\tSegment}, \F) \satisfies \inv$, as
  $\vci{\F}{\inv}$ holds. If $\tSegment$ has a return statement then,
  $\tSegment$ is a whole-trace-segment, $\subTrace = \tSegment =
  \trace$ and $\return{\subTrace} = \F(\n)$ holds because of
  $\vci{\F}{\inv}$.

  Inductive case: Assuming $P(0), P(1) \cdots P(n)$ and
  proving $P(n+1)$. Let $\tSegment =
  \segment{\trace}{n+1}$. $\tSegment_{pre} = \segment{\trace}{n}$. Let
  $\trace_{pre}$ be a trace such that
  $\segDepth{\tSegment_{pre}}{\trace_{pre}} = 1$.
  $\atEntry{\tSegment} = \atEnd{\tSegment_{pre}}$ ,thus
  $(\atEntry{\tSegment}, \F) \satisfies \inv$. Now, we have 3 cases
  depending upon whether $\tSegment$ is a prefix, suffix or a whole
  trace segment.

  \begin{enumerate}
  \item If $\tSegment$ is prefix-trace-segment.\\
    We have $\tSegment_{pre}$ is a prefix-trace-segment.  Next,
    $(\atEnd{\tSegment},\F) \satisfies \inv$ as \\$\vci{\F}{\inv}$
    holds.

  \item If $\tSegment$ is a whole-trace-segment.\\
    We have $\trace_{pre}$ is a prefix-trace-segment. $\tSegment =
    \subTrace$ as $\tSegment$ is a whole-trace-segment and from
    $\vci{\F}{\inv}$ we have \\$(\atEnd{\subTrace}, \F) \satisfies \inv$
    and $\return{\subTrace} = \F(\n)$.

  \item If $\tSegment$ is suffix-trace-segment.\\
    $\tSegment_{pre}$ is either a suffix-trace-segment or a
    whole-trace-segment, and from the
    inductive hypothesis we have $\return{\trace_{pre}} = \F(\n)$. let
    $\tSegment_{other}$ be the other trace-segment in trace
    $\subTrace$, $\tSegment_{other}$ is a
    prefix-trace-segment. $\tSegment_{other} = \segment{\trace}{y}$
    and $y < n$, because of the structure of trace $\subTrace$. Trace
    $\subTrace$ is equivalent to trace-segment $\tSegment_{other}$ followed by a
    recursive call, then followed by trace-segment $\tSegment$.  Also
    $\atEntry{\subTrace} = \atEntry{\tSegment_{other}}$, thus
    $(\atEntry{\subTrace}, \F)
    \satisfies \inv$ from the inductive hypothesis. Also
    $\beforeCall{\subTrace} = \atEnd{\tSegment_{other}}$, and from the
    inductive hypothesis we have $(\atEnd{\tSegment_{other}}, \F)
    \satisfies \inv$, thus $(\beforeCall{\subTrace}, \F)
    \satisfies \inv$. Now, as $\vci{\F}{\inv}$ holds we
    have, $(\atEnd{\subTrace}, \F) \satisfies \inv$ and
    $\return{\subTrace} = \F(\n)$.
  \end{enumerate}
  
  Hence proved.
\end{proof}

\begin{theorem} \label{theorem:swopGivesWop}
  Let $\inv$ be a formula and $\F$ be a function such that
  \\$\OPCheckE\mi{(\inv : invariant, \pathCondition : path \;
    condition)}$ returns formula $\formula$ and $\F \satisfies
  \formula$. Then procedure `\foo' is observationally pure wrt all
  global states $\gstate$ such that $(\gstate, \F) \satisfies \inv$.
\end{theorem}


\section{Impurity witness approach}\label{sec:impurityWitness}

\begin{figure}[htp]
  \begin{algorithm}[H]
    \begin{align*}
      \OPCheckA &\mi{(\inv : invariant,
        \pathCondition: path\; condition)} \equiv &\\
      &\inv[\g_\alpha/\g] \wedge \inv[\g_\beta/\g]  & (1)\\
      & \wedge \inv[\gaft_{\alpha1}/\g] \wedge
      \inv[\gaft_{\alpha2}/\g] \cdots \wedge \inv[\gaft_{\alpha m}/\g]
      & (2)\\
      & \wedge \inv[\gaft_{\beta1}/\g] \wedge \inv[\gaft_{\beta2}/\g]
      \cdots \wedge \inv[\gaft_{\beta m}/\g] & (3)\\
      &\wedge \n_\alpha = \n_\beta  & (4)\\
      &\wedge \pathCondition[\g_\alpha/\g, \n_\alpha/\n, \retVar_\alpha/\retVar,
        \gout_\alpha/\gout, & (5)\\
        &\gbef_{\alpha1}/\gbef_1 \cdots, \gaft_{\alpha 1}/\gaft_1, \cdots
        \gaft_{\alpha m}/\gaft_m]  & (6)\\
      &\wedge \pathCondition[\g_\beta/\g, \n_\beta/\n, \retVar_\beta/\retVar,
        \gout_\beta/\gout, & (7)\\
        &\gbef_{\beta1}/\gbef_1 \cdots, \gaft_{\beta 1}/\gaft_1, \cdots
        \gaft_{\beta m}/\gaft_m] & (8)\\
      &\wedge (\retVar_\alpha \neq \retVar_\beta \vee \neg\inv[\gbef_{\alpha1}/\g] \vee
       \cdots \neg\inv[\gbef_{\alpha m}/\g] & (9) \\
        &\vee \neg\inv[\gout_\alpha/\g])  & (10)\\
    \end{align*}
    \caption{Impurity witness : produces a formula whose unsatisfiability
    implies observational purity.}
    \label{algo:pairwiseOPcheckCombined}
  \end{algorithm}  
\end{figure}

The impurity witness approach in
Algorithm~\ref{algo:pairwiseOPcheckCombined} encodes a formula
$\formula_{iw}$. If $\formula_{iw}$ is UNSAT the given procedure is
OP. The idea encoded in $\formula_{iw}$ is that if a pair of traces of
the given procedure exists such that the traces start with the same
parameter value, and potentially different values for the global
variables return different results, then the procedure is not OP. In
this case, we have a witness to the non-OPness of the given
procedure. Otherwise, we prove that the given procedure is OP.

The check encoded in Figure~\ref{algo:pairwiseOPcheckCombined}, cannot
be expressed in standard requires and ensures (again, to the best of
our knowledge). As the approach compares the given procedure with
itself, standard requires and ensures do not suffice. But works such as
\cite{lahiri2013differential} can be extended to express this. 

\subsection{Proof of Correctness}
In this section we will prove that if Impurity witness procedure
(Algorithm~\ref{algo:pairwiseOPcheckCombined}) returns formula
$\formula$ for procedure `\foo' and $\formula$ is UNSAT then procedure
`\foo' is observationally pure.

The formula produced by $\OPCheckA \mi{(\inv, \pathCondition)}$
for \label{opcheckBreakdown} simplicity can be broken down into two
parts. Let the formula produced by $\OPCheckA \mi{(\inv,
  \pathCondition)}$ be $\pairFormula$ and $\pairFormula = \formula_1
\wedge \formula_2$.\\
Where $\formula_1$ is : conjucts in line (1) $\cdots$ (8) in
Algorithm~\ref{algo:pairwiseOPcheckCombined}.\\
And $\formula_2$ is : conjucts in line (9) and (10) in
Algorithm~\ref{algo:pairwiseOPcheckCombined}.\\

\begin{lemma}\label{lemma:funcRef}
  $\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies
  \retVar_1 = \F_{outer}(n_1)$, $\forall \F \forall(X) \formula_1
  \implies \retVar_1 = \retVar_2$ and $\forall \F \exists \F_{outer}
  \forall (X) \formula_1 \implies \retVar_1 = \F_{outer}(n_1) =
  \retVar_2$ be formulae $\formula_{func}$, $\formula_{ret}$ and $\formula_3$
  respectively then $\formula_{func} = \formula_{ret} = \formula_3$.
\end{lemma}

\begin{lemma}\label{lemma:forAllOuterAInner}
  Let $\forall \F \exists \F_{outer} \forall (X) \formula_1
  \implies (\neg \formula_2 \wedge \retVar_1 = \F_{outer}(\n_1))$ and
  $\forall \F \forall (X) \formula_1 \implies \neg \formula_2$ be
  $\formula_3$ and $\formula_4$ respectively. $\formula_3$ and
  $\formula_4$ are equivalent.
\end{lemma}

\begin{lemma}\label{lemma:combiningF}
  Let $\exists \F \forall (X) \formula_1 \implies (\neg \formula_2
  \wedge \retVar_1 = \F(\n_1))$ and $\forall \F \exists \F_{outer}
  \forall (X) \formula_1 \implies (\neg \formula_2 \wedge \retVar_1 =
  \F_{outer}(\n_1))$ be Formulae $\formula_{merged}$ and
  $\formula_{outer}$ respectively. Then $\formula_{outer} \implies
  \formula_{merged}$.
\end{lemma}


\begin{lemma} \label{lemma:pairwise}
  Let $\inv$ be any formula, $\pathCondition$ be a path condition for
  procedure `\foo', \\$\OPCheckA \mi{(\inv, \pathCondition)}$ return
  formula $\pairFormula$ such that $\pairFormula$ is
  unsatisfiable, $\inv$ is satisfiable and $\OPCheckE \mi{(\inv,
    \pathCondition)}$ returns formula $\formula'$ then $\formula'$ is
  satisfiable.
\end{lemma}

\begin{theorem} \label{theorem:impurityWitness}
  Let $\inv$ be an invariant, $T$ be a path condition,
  $\OPCheckA \mi{(\inv, T)}$ return formula $\formula$ such that
  $\formula$ is UNSAT, $\inv$ is SAT. Method `\foo' is
  observationally pure for all states $\state$ such that $\state
  \satisfies \inv$.
\end{theorem}

\section{Comparing the two approaches}

\begin{lstlisting}[caption={Procedure `bar': illustrates that
      existential approach is more precise that the impurity witness
      approach.}, label=lst:comparison]
int bar(int n) { 
  return g; 
}
\end{lstlisting}

The existential approach in Section~\ref{sec:existential} is more
precise than the impurity witness approach in
Section~\ref{sec:impurityWitness}. The existential approach requires
one mathematical function, such that it mimics the given procedure and
the invariant holds for this function to mark a procedure OP. On the
other hand, the impurity witness marks a procedure OP if for all
functions, the two instances of the path condition agree on the return
value. For instance procedure `bar' in Listing~\ref{lst:comparison} is
observationally pure for the invariant $(g = \F(0) \vee g = \F(1))$
and it mimics the mathematical function $\forall n. \F(0) = \F(1) =
\F(n)$ (thus, it must be a constant function). Now, the existential
approach marks this procedure as OP whereas the impurity witness
approach marks it as non-OP. The existential approach marks this
example OP, considering a function $\lambda n. 2$. Whereas there are
many functions $\F'$ such that $\F'(0) \neq \F'(1)$, now the procedure
`bar' is not OP for the invariant $(g = \F(0) \vee g = \F(1))[\F'/\F]$.

Although the existential approach is more precise, the impurity
witness approach performs better with SAT-SMT solvers. In case of the
existential approach the solver has to find a satisfying assignment
for the free variable $\F$. Whereas, in case of the impurity witness
approach, the inequivalence is contradicted (if procedure is OP) using
FOL with interpreted functions.

\section{Experimental Results}

(to be included)
%% \section{Conclusion}
\section{Related work}
JML does not allow any side-effects for Library procedures, thus
specifiers use pure replacements instead. Barnett defines
Observational purity~\cite{barnett200499} but their work cannot prove
self recursive procedures to be OP and also need user
annotations. They use a information flow based technique to prove OP
of procedures.

The idea of comparing a program to itself~\cite{lahiri2013differential}
\cite{partush2013abstract} is closely related to the impurity witness
approach. DAC~\cite{lahiri2013differential} uses this idea for
finding the assertions that failed in a version of a program with
respect to another version. Whereas, Partush and
Yahav~\cite{partush2013abstract} focus on finding the parameter values
for which the two versions of the procedure differ.

Naumann~\cite{naumann2007observational} calls a procedure OP if it is
output-equivalent to a procedure which is a side-effect free. And
side-effect-freeness does not entail OPness. This works present/use
a theory for simulations, closely related to ownership types. Thus
this work is closely related but they solve a different problem.

Cok~\cite{cok2008extensions} builds upon Barnett's
work~\cite{barnett2006allowing} and~\cite{barnett200499} suggests
partitioning the set of methods into ``pure'', ``secret'' and ``query''
methods, each scoped to a particular data group. The query methods are
OP. They give a set of rules to be followed by methods in each
group. Thus, structuring for modular reasoning about OPness.

Finifter~\cite{cok2008extensions} takes a different approach of restricting
the programming language in order to make OP checking simpler. In the
restricted language called Joe-E, OP methods have all objects reachable
from the parameters marked as immutable.

Salcianu~\cite{sualcianu2005purity} gives a static analysis
that checks if a method modifies the pre-existing state. All the
operators used in specifications do not have side effects. If a
procedure does not modify the pre-existing state it is called pure and
~\cite{barnett200499} suggests that such procedures can be used in
specifications. Our work in comparison generalizes further by
allowing procedures that modify pre-existing state but behave as
mathematical functions in specifications. We would like to point out
that in their work they manually marked library methods that did
caching but were semantically preserving as pure.

\nocite{barnett2004spec}
\nocite{lahiri2013differential}
\nocite{de2008z3}
\nocite{alpern1988detecting}
\nocite{sondergaard1990referential}
\nocite{flanagan2001avoiding}
\nocite{sualcianu2005purity}
\nocite{cytron1991efficiently}
\nocite{leino2008boogie}


%% \appendix
\begin{subappendices}
\renewcommand{\thesection}{\Alph{section}}


\section{Proof of Lemma~\ref{lemma:interface}}

\begin{proof}
  In Algorithm~\ref{algo:someOPcheckCombined} the returned formula is
  $\formula$ and $\F' \satisfies \formula$. Lets substitute $\F'$ in
  $\formula$ for the free variable $\F$ to get $(\forall \g) (\forall
  \n) (\forall \retVar) (\forall \gout) (\forall \gbef_1) (\forall
  \gbef_2) \cdots \\(\forall \gaft_1) (\forall \gaft_2) \cdots \{\inv[\F'/\F]
  \wedge \pathCondition[\F'/\F] \wedge \inv[\gaft_1/\g, \F'/\F] \wedge
  \\\inv[\gaft_2/\g, \F'/\F] \cdots \implies (\retVar = \F'(\n) \wedge
  \inv[\gout/\g, \F'/\F] \wedge \inv[\gbef_1/\g, \F'/\F] \wedge
  \inv[\gbef_2/\g, \F'/\F]
  \cdots) \}$, lets call this formula $\formula'$.

  $\formula'$ is valid, since $\F' \satisfies \formula$ and $\formula'
  = \formula[\F'/\F]$. Let $x$ be a trace or a trace segment, such
  that $(\atEntry{x}, \F') \satisfies \inv$ then
  \begin{enumerate}
  \item if $x$ is a trace.
    \begin{enumerate}
    \item if $x$ has a recursive call
      \begin{enumerate}
      \item \label{beforeCallInRec} $(\beforeCall{x}, \F') \satisfies
        \inv$ holds as the conjuncts in the conclusion of $\formula'$,
        \\$\inv[\gbef_1/\g, \F'/\F]$, $\inv[\gbef_2/\g, \F'/\F] \cdots
        \inv[\gbef_n/\g, \F'/\F]$ are satisfied for each $i^{th}$ call
        statement.
      \item the premise in $\formula'$, the conjunct
        $\pathCondition[\F'/\F]$, constraints the recursive call's
        return value to respect function $\F'$. Next, the 
        conclusion in formula $\formula'$ has the conjuncts
        $\inv[\gout/\g,  \F'/\F]$ and $\retVar = \F'(\param{x})$. Thus,
        $(\atEnd{x}, \F') \satisfies \inv$ and $\return{x} =
        \F'(\param{x})$.
      \end{enumerate}
    \item if $x$ does not have a recursive call.\\ In the conclusion
      in formula $\formula'$, we have $\inv[\gout/\g, \F'/\F]$ and\\
      $\retVar = \F'(\param{x})$. Thus, we have $(\atEnd{x}, \F')
      \satisfies \inv$ and $\return{x} = \F'(\param{x})$.
    \end{enumerate}
  \item If $x$ is a prefix trace segment \\we have, 
    trace $\trace$ must exist such that $\segDepth{x}{\trace} =
    1$. And we have\\ $(\atEntry{x}, \F') \satisfies \inv$. Now we can
    apply the above mentioned point \ref{beforeCallInRec}, we get
    $(\beforeCall{\trace}, \F') \satisfies \inv$, and
    $\beforeCall{\trace} = \atEnd{x}$. Thus, we have $(\atEnd{x}, \F')
    \satisfies \inv$.
  \end{enumerate}
  
  Hence proved.
\end{proof}

\section{Proof of theorem~\ref{theorem:swopGivesWop}}
\begin{proof}
  Inductive hypothesis $P(k)$ : Let $\inv$ be an invariant, $\history$
  be a history, $\gstate$ be a global state, such that $(\atEntry{\history},
  \F) \satisfies \inv$, $(\gstate, \F)
  \satisfies \inv$, the $k^{th}$ trace in $\history$ be $\trace_k$
  then $(\atEntry{\trace_k}, \F) \satisfies \inv$, $(\atEnd{\trace_k},
  \F) \satisfies \inv$ and $\return{\trace_k} = \F(\n_k)$ where $\n_k$
  is the argument to trace $\trace_k$.
  
  Base case : Let trace $\trace_1$ be the first trace of history
  $\history$ and since $\atEntry{\history} = \atEntry{\trace_1}$ we
  have $(\atEntry{\trace_1}, \F) \satisfies \inv$. From
  lemma~\ref{lemma:trace} we have $(\atEnd{\trace_1}, \F) \satisfies
  \inv$, and also $\return{\trace_1} = \F(\n_1)$.
  
  Inductive case : Assuming P(k) and proving P(k + 1). From the
  inductive hypothesis we have $(\atEnd{\trace_k}, \F) \satisfies
  \inv$. Also, $\atEnd{\trace_k} = \atEntry{\trace_{k+1}}$. Thus,
  $(\atEntry{\trace_{k+1}}, \F) \satisfies \inv$ and from
  lemma~\ref{lemma:trace}, we can conclude $(\atEnd{\trace_{k+1}}, \F)
  \satisfies \inv$ and $\return{\trace_{k+1}} = \F(\n_{k+1})$ where
  $\n_{k+1}$ is the argument to $\trace_{k+1}$.

  Hence proved.
\end{proof}


\section{Proof of Lemma~\ref{lemma:funcRef}}
\begin{proof}
  We will prove that both $\formula_{func}$ and $\formula_{ret}$ are
  equivalent to formula $\formula_3$.
  \begin{enumerate}
  \item Proving $\formula_{func}$ and $\formula_3$ equivalent.\\
    In formula $\formula_1$ there are two instances of
    $\pathCondition$. For one instance of $\pathCondition$ variable $\retVar$ is renamed
    to $\retVar_1$ whereas for the other, it is renamed to
    $\retVar_2$. And all variables have equivalent
    constraints.
    Thus, if there exist 
    an assignment for one instance of sub-formula
    $\pathCondition$ in $\formula_1$, the same assignment can be
    mapped to the other instance of $\pathCondition$.
    %% is also and assignment for the
    %% other instance
    Hence $\retVar_1 = \retVar_2$.\\
    Thus, we have $\formula_{func}$ and $\formula_3$ are equivalent.
  \item Proving $\formula_{ret}$ and $\formula_3$ equivalent.\\
    Here we will show that given $\formula_{ret}$ is valid, we can
    construct a function $\F$ such that for each domain value $n_1$,
    it would map it function $\F$ to value $\retVar_1$.
    
    Proving by contradiction. Let us assume that $\formula_{ret}$
    holds, but we cannot construct a
    function $\F$ such that it would be equivalent to $\retVar_1$ for
    each domain value. Let us consider the case that a value
    from the domain is not mapped to a unique value in the range.
    Since function $\F$ maps 
    %% (see section \ref{onlyTerminatinTraces}). Since function $\F$ maps
    variable $\n_1$ to $\retVar_1$ and such a function cannot exist;
    it means that $\retVar_1 \neq \retVar_2$ is possible, which
    implies $\formula_{ret}$ is not valid.
    %% The other
    %% case is that a value from the domain is not mapped to an element
    %% in the range. Such a case would arise if the trace is non
    %% terminating. And in this case both the formulae are true.
    Hence this
    is a contradiction.

    Hence proved.
  \end{enumerate}
\end{proof}

\section{Proof of Lemma~\ref{lemma:forAllOuterAInner}}
\begin{proof}
\begin{align*}
  \formula_3 =&\\
  &\forall \F \exists \F_{outer} \forall (X) \formula_1
  \implies (\neg \formula_2 \wedge \retVar_1 = \F_{outer}(\n_1))\\
=&\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies
(\neg(\retVar_1 \neq \retVar_2 \\
&\vee \neg\inv[\gbef_{p1}/\g] \vee \neg\inv[\gbef_{p2}/\g] \cdots 
\vee \neg\inv[\gout/\g]) \wedge\\
&\retVar_1 = \F_{outer}(\n_1))\\
=&\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies
(\retVar_1 = \retVar_2 = \F_{outer}(\n_1) \wedge\\
&\inv[\gbef_{p1}/\g] \wedge \inv[\gbef_{p2}/\g] \cdots \wedge \inv[\gout/\g])\\
=&\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies
(\retVar_1 = \retVar_2 = \F_{outer}(\n_1)) \wedge\\
&\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies
\inv[\gbef_{p1}/\g] \wedge
\inv[\gbef_{p2}/\g]\\
&\cdots \wedge \inv[\gout/\g]\\
=&\forall \F \forall (X) \formula_1 \implies
\retVar_1 = \retVar_2 \wedge  &(lemma~\ref{lemma:funcRef})\\
&  \forall \F \exists \F_{outer} \forall (X) \formula_1 \implies (
\inv[\gbef_{p1}/\g] \wedge \\
&\inv[\gbef_{p2}/\g] \cdots \wedge \inv[\gout/\g])\\
=&\forall \F \forall (X) \formula_1 \implies
\retVar_1 = \retVar_2 \wedge &(\F_{outer} \not \in free\mhyphen
var(a) a \in \{\formula_1, \inv\})\\
&\forall \F \forall (X) \formula_1 \implies (
\inv[\gbef_{p1}/\g] \wedge \inv[\gbef_{p2}/\g] \cdots \wedge\\
&\inv[\gout/\g])\\
=&\forall \F \forall (X) \formula_1 \implies (
\retVar_1 = \retVar_2 \wedge \inv[\gbef_{p1}/\g] \wedge \\
&\inv[\gbef_{p2}/\g] \cdots \wedge \inv[\gout/\g])\\
=&\forall \F \forall (X) \formula_1 \implies \neg
\formula_2\\
=& \formula_4\\
%% =&\forall \F \forall (X) \formula_1 \implies
%% \retVar_1 = \retVar_2 \wedge
%% &(\F_{outer} \not \in free\mhyphen variable(\formula_1))\\
%% &\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies (
%% \inv[\gbef_{p1}/\g] \wedge \inv[\gbef_{p2}/\g] \cdots \wedge
%% \inv[\gout/\g])\\
%% =&\forall \F \forall (X) \formula_1 \implies
%% \retVar_1 = \retVar_2 = \F(n_1) \wedge
%% & (lemma~\ref{lemma:funcRef})\\
%% &\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies (
%% \inv[\gbef_{p1}/\g] \wedge \inv[\gbef_{p2}/\g] \cdots \wedge
%% \inv[\gout/\g])\\
%% =&\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies (
%%  \retVar_1 = \retVar_2 = \F(n_1)\wedge\\
%% &\inv[\gbef_{p1}/\g] \wedge \inv[\gbef_{p2}/\g] \cdots \wedge
%%  \inv[\gout/\g])\\
%%  =&\forall \F \exists \F_{outer} \forall (X) \formula_1 \implies (
%%  \neg \formula_2 \wedge \retVar_1 = \F(n_1))\\
%%  =& \formula_3
\end{align*}
Hence proved.
\end{proof}

\section{Proof of Lemma~\ref{lemma:combiningF}}

\begin{proof}
  Assuming $\formula_{outer}$ is valid we will inductively build a
  function $\F'$ such that we can substitute it for both functions
  $\F$ and $\F_{outer}$ in formula $\formula_{outer}$. Thus,
essentially finding a function that satisfies formula
$\formula_{merged}$.


  %% $(\forall (X) \formula_1 \implies (\neg
  %% \formula_2 \wedge \retVar_1 = \F(\n_1)))[\F'/\F]$ is valid.

  %% In order to build this function $\F'$ we need tools to traverse over
  %% the domain of $\F'$ with respect to the formula
  %% $\formula_{outer}$. The following are the definitions.
We will use the following definitions to traverse the domain of
function $\F'$ with respect to formula $\formula_{outer}$.

  \begin{definition}[depth(dom $\F \rightarrow \integer$)]
$\depth{n} = 1 + min(\depth{k})$ where $n \in dom \;\F'$ such that
$(\forall (X) \formula_1 \implies (\neg
  \formula_2 \wedge \retVar_1 =
\F_{outer}(\n_1)))[\F'(\n)/\F_{outer}(\n_1),\\ \F'(k)/\F(k_1),
\F'(k)/\F(k_2)]$ is valid, where $k_1$ and $k_2$ are the arguments to
the inner procedure calls in the two instances of $\pathCondition$ in
formula $\formula_1$. Next, $x$ such that $x \in dom \; \F'$ has depth
0 if in the above mentioned formula by substituting $x$ for $\n$ leads
to a case such that value of $\retVar_1$ is independent of $k_1$.

    %% value $\F(k)$ is substituted in formula $\formula_{outer}$ to get
    %% the mapping for $n$. $\depth{n} = 0$ if no substitutions are
    %% necessary to get the mapped value for $n$.
  \end{definition}

  \begin{definition}[level($\integer$) $\rightarrow$ subset of dom $\F$]
    $\level{n}$ gives the set $X$ of domain elements of $\F$ such
    $\forall v \in X \depth{v} \leq n$.
\end{definition}

  Inductive hypothesis $P(n)$ : Let $\formula_{outer}$ be valid then
  there exist a function $\F'$ such that $\forall k \in \level{n}
  \implies \{\forall (X-\{n_1\}) \formula_1 \implies (\neg
  \formula_2 \wedge \retVar_1 = \F_{outer}(\n_1))\}[\F'/\F_{outer},
    k/n_1, \F'/\F]$.

Base case $P(0)$ : Let $p \in \level{0}$. The corresponding value for
$p$ can be produced only if $\pathCondition$ has a disjunct which does
not refer the function $\F$, otherwise $\level{0}$ is an empty set. If
$\level{0}$ is not an empty set then, it satisfies the inductive
hypothesis, as all satisfying functions replacing $\formula_{outer}$
respect each other on these arguments. This is because the mappings
are essentially encoded in the formula itself and $\formula_{outer}$
holds. If $\level{0} = \phi$ then the hypothesis holds vacuously.

%% $\level{0}$ can be empty only if procedure `\foo' does
%%   not have a base case thus, `\foo' never terminates; in this case we
%%   are done. If $\level{0}$ is not empty, since $\formula_{outer}$ is
%%   valid we have that for all functions substituted for the inner
%%   procedure call, there exists a function that respects the value
%%   $\retVar$; function $\F'$ also respects $\retVar$.
  
Inductive case : Assuming $P(k)$ holds, proving for $P(k+1)$. We have
that up-to the $k^{th}$ level there exists a function $\F'$ that
satisfies the inductive hypothesis. Next, we can find the values of
the $\n$ such that it leads to an element of the set $\level{k}$ as
the argument to the inner procedure call in procedure $\foo$. Thus,
essentially giving us the elements of set $\level{k+1}$.  And for all
such newly discovered members of set $\level{k+1}$ we have that the
inductive hypothesis holds as we know that $\formula_{outer}$
holds. This is because in $\formula_{outer}$, for all functions that
replace the inner procedure call, there exists a function
$\F_{outer}$, which represents the return value.


%% We
%%   have that up-to the $n^{th}$ level there exists a function $\F'$ that
%%   satisfies $\formula_{merged}$. Next, because $\formula_{outer}$
%%   holds, we have $\formula_{merged}$ also holds up-to $\level{n+1}$ as
%%   $\formula_{merged}$ holds up-to $\level{n}$ and $\formula_{outer}$, so we
%%   can substitute $\F$ with $\F'$ up-to $\level{n}$. This also describes
%%   function $\F'$ for $\level{n}$.
  
Hence proved.
\end{proof}

\section{Proof of Lemma~\ref{lemma:pairwise}}

\begin{proof}
  Let $X$ be the set of free variables in formula
  $\pairFormula$ except the mathematical function $\F$. We have
  $\pairFormula = \formula_1 \wedge \formula_2$. Formula
  $\formula_1$ and $\formula_2$ are listed above in Section
  \ref{opcheckBreakdown}.
  
  $\pairFormula$ is UNSAT; it is equivalent to say $\exists \F
  \exists(X) \pairFormula$ is false. Thus, we have $\forall \F
  \forall (X) \neg \pairFormula$ is true. Next, we have $\forall \F
  \forall (X) \neg \pairFormula = \forall \F \forall (X) \neg(
  \formula_1 \wedge \formula_2) = \forall \F \forall (X) \neg
  \formula_1 \vee \neg \formula_2 = \forall \F \forall (X) \formula_1
  \implies \neg \formula_2$. Let $\formula_3 = \forall \F \forall (X)
  \formula_1 \implies \neg \formula_2$.

  Next, we have the following properties :
  \begin{enumerate}
  \item $\formula_{pairwise}$ is unsatisfiable $\implies \formula_3$
    is valid (illustrated above). 
  \item Let $\forall \F \exists \F_{outer} \forall (X) \formula_1
  \implies (\neg \formula_2 \wedge \retVar_1 = \F_{outer}(\n_1))$ be
  formula $\formula_4$
    From lemma~\ref{lemma:forAllOuterAInner} we have $\formula_3 =
    \formula_4$.
  \item Let $\formula_{merged}$ be $\exists \F \forall (X) \formula_1
    \implies (\neg \formula_2 \wedge \retVar_1 = \F(\n_1))$. From
    lemma~\ref{lemma:combiningF} we have $\formula_4 \implies
    \formula_{merged}$. 
  \item Since formula $\formula_{merged}$ holds we have $\forall (X) \formula_1
    \implies (\neg \formula_2 \wedge \retVar_1 = \F(\n_1))$ is
    Satisfiable. Thus, $\formula'$ is satisfiable.
  \end{enumerate}
Hence proved.
\end{proof}

\section{Proof of Theorem~\ref{theorem:impurityWitness}}

\begin{proof}
  We have $\OPCheckA \mi{(\inv, T)}$ for method `\foo' returns formula
  $\formula$ such that $\formula$ is UNSAT. From
  lemma~\ref{lemma:pairwise} we have that $\OPCheckE \mi{(\inv, T)}$
  would return formula $\formula'$ such that $\formula'$ is SAT, which
  implies that `\foo' is static observationally pure. Hence we
  can apply theorem~\ref{theorem:swopGivesWop}.\\
  Hence proved.
\end{proof}

\end{subappendices}

%

%
% ---- Bibliography ----
%
%% \bibliographystyle{plainnat}
\bibliographystyle{splncs}
\bibliography{references}
%% \begin{thebibliography}{5}

%% \bibitem {clar:eke}
%% Clarke, F., a, I.:
%% Nonlinear oscillations and
%% boundary-value problems for Hamiltonian systems.
%% Arch. Rat. a. Anal. 78, 315--333 (1982)


%% \end{thebibliography}

\end{document}
